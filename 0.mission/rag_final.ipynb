{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2004ba21",
   "metadata": {},
   "source": [
    "RAG - Loader(UpstageDocumentParseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œë” ì‹¤í–‰\n",
    "from dotenv import load_dotenv\n",
    "from langchain_upstage import UpstageDocumentParseLoader\n",
    "\n",
    "file_path = \"./test_modified.pdf\"\n",
    "\n",
    "loader = UpstageDocumentParseLoader(\n",
    "    file_path,\n",
    "    split=\"page\",  # í˜ì´ì§€ë³„ë¡œ ë¶„í• \n",
    "    output_format=\"markdown\",  # í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥\n",
    "    ocr=\"auto\",  # ìë™ OCR ì‚¬ìš©\n",
    "    coordinates=True,  # ì¢Œí‘œ ì •ë³´ í¬í•¨\n",
    ")\n",
    "\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fa30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs[21].page_content)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44f9b7",
   "metadata": {},
   "source": [
    "Rag - Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#  ë¬¸ì„œ ìë¥´ê¸° (AIê°€ ì½ê¸° ì‰¬ìš´ í¬ê¸°ë¡œ ìª¼ê°œê¸°)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "docs_splitter = splitter.split_documents(docs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3aab1",
   "metadata": {},
   "source": [
    "Rag - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78aeb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"mps\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52858f3",
   "metadata": {},
   "source": [
    "Rag - Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72f2ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "\n",
    "# ì˜¬ë°”ë¥¸ ë³€ìˆ˜ëª… ì‚¬ìš©\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs_splitter,  # ê¸°ì¡´ ë³€ìˆ˜ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "    embedding=hf_embeddings,  # ì„ë² ë”© ëª¨ë¸\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647a517",
   "metadata": {},
   "source": [
    "Rag - retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27a3da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "    search_kwargs={\"k\": 5},  # ìƒìœ„ 5ê°œ ê²°ê³¼ ë°˜í™˜\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cfc99",
   "metadata": {},
   "source": [
    "Rag - Formatting / Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30217fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì„¤ì • (ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”)\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\", temperature=0, streaming=True)\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ\n",
    "chat_history = InMemoryChatMessageHistory()\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG + ë©€í‹°í„´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ AI ë¹„ì„œì•¼. \n",
    "        ì œê³µëœ ë¬¸ì„œ ë‚´ìš©(context)ê³¼ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µí•´.\n",
    "        ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ëŒ€ë‹µí•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•´ì„œ ë‹µë³€í•´.\n",
    "        \n",
    "        ì°¸ê³  ë¬¸ì„œ:\n",
    "        {context}\n",
    "        \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„± (ë©€í‹°í„´ ì§€ì›)\n",
    "rag_multiturn_chain = (\n",
    "    {\"context\": retriever | format_docs, \"input\": lambda x: x[\"input\"]}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f085836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_chat_history(history_obj, max_turns=3):\n",
    "    \"\"\"ìµœê·¼ 'max_turns'ë²ˆì˜ ì‚¬ìš©ì-AI ëŒ€í™”ë§Œ ë‚¨ê¸°ê¸°\"\"\"\n",
    "    max_messages = max_turns * 2\n",
    "    if len(history_obj.messages) > max_messages:\n",
    "        deleted_count = len(history_obj.messages) - max_messages  \n",
    "        for _ in range(deleted_count):\n",
    "            history_obj.messages.pop(0)\n",
    "\n",
    "\n",
    "def stream_rag_multiturn_response(user_input):\n",
    "    \"\"\"RAG + ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬\"\"\"\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì €ì¥\n",
    "    chat_history.add_user_message(user_input)\n",
    "\n",
    "    # íˆìŠ¤í† ë¦¬ ì œí•œ ì ìš©\n",
    "    limit_chat_history(chat_history)\n",
    "\n",
    "    print(f\"ğŸ™‹ ì‚¬ìš©ì: {user_input}\")\n",
    "    print(\"ğŸ¤– AI: \", end=\"\", flush=True)\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    try:\n",
    "        response = \"\"\n",
    "        # # í”„ë¡¬í”„íŠ¸ì— íˆìŠ¤í† ë¦¬ ì§ì ‘ ë°”ì¸ë”©\n",
    "        prompt_with_history = prompt.partial(chat_history=chat_history.messages[:-1])\n",
    "\n",
    "        # ì²´ì¸ ì¬êµ¬ì„±\n",
    "        chain_with_history = (\n",
    "            {\"context\": retriever | format_docs, \"input\": lambda x: x}\n",
    "            | prompt_with_history\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°\n",
    "        for chunk in chain_with_history.stream(user_input):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "            response += chunk\n",
    "\n",
    "        print()  # ì¤„ë°”ê¿ˆ\n",
    "\n",
    "        # AI ì‘ë‹µ ì €ì¥\n",
    "        chat_history.add_ai_message(response)\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66854ea8",
   "metadata": {},
   "source": [
    "Rag - Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bccbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤\n",
    "def interactive_chat():\n",
    "    \"\"\"ëŒ€í™”í˜• ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ¤– RAG ì±—ë´‡ ì‹œì‘!\")\n",
    "    print(\"ğŸ’¡ 'ì¢…ë£Œ' ì…ë ¥ ì‹œ ëŒ€í™”ë¥¼ ëëƒ…ë‹ˆë‹¤.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nğŸ™‹ ì‚¬ìš©ì: \").strip()\n",
    "\n",
    "                if user_input.lower() == \"ì¢…ë£Œ\":\n",
    "                    print(\"ğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!\")\n",
    "                    break\n",
    "\n",
    "                \n",
    "                # stream_rag_multiturn_response(user_input)\n",
    "\n",
    "                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬\n",
    "                stream_rag_multiturn_response(user_input)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        chat_history.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba8109",
   "metadata": {},
   "source": [
    "Rag - QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3a2ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤– RAG ì±—ë´‡ ì‹œì‘!\n",
      "ğŸ’¡ 'ì¢…ë£Œ' ì…ë ¥ ì‹œ ëŒ€í™”ë¥¼ ëëƒ…ë‹ˆë‹¤.\n",
      "============================================================\n",
      "ğŸ™‹ ì‚¬ìš©ì: ì•ˆë…•\n",
      "ğŸ¤– AI: ì•ˆë…•í•˜ì„¸ìš”! ì•„ì£¼ëŒ€í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”. ì œê°€ ìµœì„ ì„ ë‹¤í•´ ë‹µë³€í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "ğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    interactive_chat()  # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb593f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710067c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf7064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
